{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 讲解在 https://zhuanlan.zhihu.com/p/107889011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
    "# !pip install numpy matplotlib spacy torchtext seaborn\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math,copy,time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_context(context=\"talk\") \n",
    "# seaborn只在最后可视化self-attention的时候用到，\n",
    "# 可以先不管或者注释掉这两行\n",
    "%matplotlib inline \n",
    "# only for jupyter notebook\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Embeddings\n",
    "\n",
    "顾名思义，Embeddings类主要负责对输入的source sequence和target\n",
    "\n",
    "sequence的词嵌入表示的映射，具体为每个词从one-hot表示，映射为d_model维度的一个向量。这样的话，如果有10个词，d_model为512的时候，则我们得到的是一个10*512的矩阵。每一行是512列，代表一个词的dense表示。\n",
    "\n",
    "“In our model, we share the same weight matrix between the two embedding layers and the pre-softmax linear transformation”,\n",
    "这句话，在没有理解他们的一篇ACL的使用词根做机器翻译的论文的前提下，其实不容易理解。例如，在做欧洲语系和英语翻译的时候，很多词是共享词根的，所以，他们这个源语言和目标语言共享一个词嵌入矩阵有一定的道理。如果是中文和英文之间，则完全没有共享词嵌入矩阵的必要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "  def __init__(self,d_model,vocab):\n",
    "    #d_model=512, vocab=当前语言的词表大小\n",
    "    super(Embeddings,self).__init__()\n",
    "    self.lut=nn.Embedding(vocab,d_model) \n",
    "    # one-hot转词嵌入，这里有一个待训练的矩阵E，大小是vocab*d_model\n",
    "    self.d_model=d_model # 512\n",
    "  def forward(self,x): \n",
    "     # x ~ (batch.size, sequence.length, one-hot), \n",
    "     #one-hot大小=vocab，当前语言的词表大小\n",
    "     return self.lut(x)*math.sqrt(self.d_model) \n",
    "     # 得到的10*512词嵌入矩阵，主动乘以sqrt(512)=22.6，\n",
    "     #这里我做了一些对比，感觉这个乘以sqrt(512)没啥用… 求反驳。\n",
    "     #这里的输出的tensor大小类似于(batch.size, sequence.length, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.PositionalEncoding （PE）位置编码\n",
    "\n",
    "\\begin{array}{l}\n",
    "P E(\\text { pos }, 2 i)=\\sin \\left(\\frac{\\text { pos }}{10000^{2 i / d_{\\text {model }}}}\\right) \\\\\n",
    "P E(\\operatorname{pos}, 2 i+1)=\\cos \\left(\\frac{\\text { pos }}{10000^{2 i / d_{\\text {model }}}}\\right)\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n例如\\n    nn.Sequential(Embeddings(d_model,src_vocab),PositionalEncoding(d_model,dropout)) \\n    # 例如，d_model=512, src_vocab=源语言的词表大小, \\n    #dropout=0.1即 dropout rate\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PositionalEncoding(nn.Module): \n",
    "  \"Implement the PE function.\" \n",
    "  def __init__(self, d_model, dropout, max_len=5000): \n",
    "    #d_model=512,dropout=0.1,\n",
    "    #max_len=5000代表事先准备好长度为5000的序列的位置编码，其实没必要，\n",
    "    #一般100或者200足够了。\n",
    "    super(PositionalEncoding, self).__init__() \n",
    "    self.dropout = nn.Dropout(p=dropout) \n",
    "\n",
    "    # Compute the positional encodings once in log space. \n",
    "    pe = torch.zeros(max_len, d_model) \n",
    "    #(5000,512)矩阵，保持每个位置的位置编码，一共5000个位置，\n",
    "    #每个位置用一个512维度向量来表示其位置编码\n",
    "    position = torch.arange(0, max_len).unsqueeze(1) \n",
    "    # (5000) -> (5000,1)\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2) * \n",
    "      -(math.log(10000.0) / d_model)) \n",
    "      # (0,2,…, 4998)一共准备2500个值，供sin, cos调用\n",
    "    pe[:, 0::2] = torch.sin(position * div_term) # 偶数下标的位置\n",
    "    pe[:, 1::2] = torch.cos(position * div_term) # 奇数下标的位置\n",
    "    pe = pe.unsqueeze(0) \n",
    "    # (5000, 512) -> (1, 5000, 512) 为batch.size留出位置\n",
    "    \n",
    "    # 一种是反向传播需要被optimizer更新的，称之为 parameter\n",
    "    # 一种是反向传播不需要被optimizer更新，称之为 buffer\n",
    "    # 模型中需要进行更新的参数注册为Parameter，不需要进行更新的参数注册为buffer\n",
    "    # 模型保存的参数是 model.state_dict() 返回的 OrderDict\n",
    "    # 模型进行设备移动时，模型中注册的参数(Parameter和buffer)会同时进行移动\n",
    "    self.register_buffer('pe', pe) \n",
    "  def forward(self, x): \n",
    "    x = x + Variable(self.pe[:, :x.size(1)], requires_grad=False) \n",
    "    # 接受1.Embeddings的词嵌入结果x，\n",
    "    #然后把自己的位置编码pe，封装成torch的Variable(不需要梯度)，加上去。\n",
    "    #例如，假设x是(30,10,512)的一个tensor，\n",
    "    #30是batch.size, 10是该batch的序列长度, 512是每个词的词嵌入向量；\n",
    "    #则该行代码的第二项是(1, min(10, 5000), 512)=(1,10,512)，\n",
    "    #在具体相加的时候，会扩展(1,10,512)为(30,10,512)，\n",
    "    #保证一个batch中的30个序列，都使用（叠加）一样的位置编码。\n",
    "    return self.dropout(x) # 增加一次dropout操作\n",
    "# 注意，位置编码不会更新，是写死的，所以这个class里面没有可训练的参数。\n",
    "\n",
    "# 有了1.Embeddings和2.PositionalEncoding；在具体使用的时候，是通过torch.nn.Sequential来把他们两个串起来的：\n",
    "'''\n",
    "例如\n",
    "    nn.Sequential(Embeddings(d_model,src_vocab),PositionalEncoding(d_model,dropout)) \n",
    "    # 例如，d_model=512, src_vocab=源语言的词表大小, \n",
    "    #dropout=0.1即 dropout rate\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.注意力模型：\n",
    "\\begin{equation}\n",
    "\\operatorname{Attention}(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}\\right) V\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None): \n",
    "# query, key, value的形状类似于(30, 8, 10, 64), (30, 8, 11, 64), \n",
    "#(30, 8, 11, 64)，例如30是batch.size，即当前batch中有多少一个序列；\n",
    "# 8=head.num，注意力头的个数；\n",
    "# 10=目标序列中词的个数，64是每个词对应的向量表示；\n",
    "# 11=源语言序列传过来的memory中，当前序列的词的个数，\n",
    "# 64是每个词对应的向量表示。\n",
    "# 类似于，这里假定query来自target language sequence；\n",
    "# key和value都来自source language sequence.\n",
    "  \"Compute 'Scaled Dot Product Attention'\" \n",
    "  d_k = query.size(-1) # 64=d_k\n",
    "  scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    # 先是(30,8,10,64)和(30, 8, 64, 11)相乘，\n",
    "    #（注意是最后两个维度相乘）得到(30,8,10,11)，\n",
    "    # 代表10个目标语言序列中每个词和11个源语言序列的分别的“亲密度”。\n",
    "    # 然后除以sqrt(d_k)=8，防止过大的亲密度。\n",
    "    # 这里的scores的shape是(30, 8, 10, 11)\n",
    "  if mask is not None: \n",
    "    scores = scores.masked_fill(mask == 0, -1e9) \n",
    "    #使用mask，对已经计算好的scores，按照mask矩阵，填-1e9，\n",
    "    #然后在下一步计算softmax的时候，被设置成-1e9的数对应的值~0,被忽视\n",
    "  p_attn = F.softmax(scores, dim = -1) \n",
    "    #对scores的最后一个维度执行softmax，得到的还是一个tensor, \n",
    "    #(30, 8, 10, 11)\n",
    "  if dropout is not None: \n",
    "    p_attn = dropout(p_attn) #执行一次dropout\n",
    "  return torch.matmul(p_attn, value), p_attn\n",
    "#返回的第一项，是(30,8,10, 11)乘以（最后两个维度相乘）\n",
    "#value=(30,8,11,64)，得到的tensor是(30,8,10,64)，\n",
    "#和query的最初的形状一样。另外，返回p_attn，形状为(30,8,10,11). \n",
    "#注意，这里返回p_attn主要是用来可视化显示多头注意力机制。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.MultiHeadedAttention\n",
    "\n",
    "\n",
    "理解了这个类，Transformer的精髓也就理解的差不多了，至于后面的Decoder或者Generator，如果自己的任务，不是双语翻译之类的，而是类似“预训练”，BERT，这种路线，则Decoder或者Generator可以完全简化。（只看一个Decoder+Generator足矣）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module): \n",
    "  def __init__(self, h, d_model, dropout=0.1): \n",
    "    # h=8, d_model=512\n",
    "    \"Take in model size and number of heads.\" \n",
    "    super(MultiHeadedAttention, self).__init__() \n",
    "    # 断言语句和 if 分支有点类似，它用于对一个 bool 表达式进行断言\n",
    "    # 如果该 bool 表达式为 True，该程序可以继续向下执行；否则程序会引发 AssertionError 错误。\n",
    "    assert d_model % h == 0 # We assume d_v always equals d_k 512%8=0\n",
    "    \n",
    "    self.d_k = d_model // h # d_k=512//8=64\n",
    "    self.h = h #8\n",
    "    self.linears = clones(nn.Linear(d_model, d_model), 4) \n",
    "    #定义四个Linear networks, 每个的大小是(512, 512)的，\n",
    "    #每个Linear network里面有两类可训练参数，Weights，\n",
    "    #其大小为512*512，以及biases，其大小为512=d_model。\n",
    "\n",
    "    self.attn = None \n",
    "    self.dropout = nn.Dropout(p=dropout)\n",
    "    \n",
    "  def forward(self, query, key, value, mask=None): \n",
    "   # 注意，输入query的形状类似于(30, 10, 512)，\n",
    "   # key.size() ~ (30, 11, 512), \n",
    "   #以及value.size() ~ (30, 11, 512)\n",
    "    \n",
    "    if mask is not None: # Same mask applied to all h heads. \n",
    "      mask = mask.unsqueeze(1) # mask下回细细分解。\n",
    "    nbatches = query.size(0) #e.g., nbatches=30\n",
    "    # 1) Do all the linear projections in batch from \n",
    "    #d_model => h x d_k \n",
    "    query, key, value = [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2) for l, x in zip(self.linears, (query, key, value))] \n",
    "      # 这里是前三个Linear Networks的具体应用，\n",
    "      #例如query=(30,10, 512) -> Linear network -> (30, 10, 512) \n",
    "      #-> view -> (30,10, 8, 64) -> transpose(1,2) -> (30, 8, 10, 64)\n",
    "      #，其他的key和value也是类似地，\n",
    "      #从(30, 11, 512) -> (30, 8, 11, 64)。\n",
    "    # 2) Apply attention on all the projected vectors in batch. \n",
    "    x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout) \n",
    "      #调用上面定义好的attention函数，输出的x形状为(30, 8, 10, 64)；\n",
    "      #attn的形状为(30, 8, 10=target.seq.len, 11=src.seq.len)\n",
    "    \n",
    "    # 3) \"Concat\" using a view and apply a final linear. \n",
    "    # contiguous：view只能用在contiguous的variable上。如果在view之前用了transpose, permute等，需要用contiguous()来返回一个contiguous copy。\n",
    "    x = x.transpose(1, 2).contiguous().view(nbatches, -1, self.h * self.d_k) \n",
    "      # x ~ (30, 8, 10, 64) -> transpose(1,2) -> \n",
    "      #(30, 10, 8, 64) -> contiguous() and view -> \n",
    "      #(30, 10, 8*64) = (30, 10, 512)\n",
    "    return self.linears[-1](x) \n",
    "    #执行第四个Linear network，把(30, 10, 512)经过一次linear network，\n",
    "    #得到(30, 10, 512)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.SubLayerConnection 子层连接\n",
    "\n",
    "所谓SubLayer，指的是两个部分：3.MultiHeadAttention以及4.PositionwiseFeedForward。\n",
    "\n",
    "特别要提的一点是，这两个子层的输入和输出，都是类似于(batch.size, sequence.length, d_model)这样的tensor。\n",
    "\n",
    "我们提前先看一下要对一个SubLayer进行Norm所需要的一个类7.LayerNorm:（更正一下，这个类用来对每个sublayer的输出进行处理，也对6层EncoderLayer之后的输出进行处理！）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.LayerNorm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        # features=d_model=512, eps=epsilon 用于分母的非0化平滑\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        # a_2 是一个可训练参数向量，(512)\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        # b_2 也是一个可训练参数向量, (512)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x 的形状为(batch.size, sequence.len, 512)\n",
    "        mean = x.mean(-1, keepdim=True) \n",
    "        # 对x的最后一个维度，取平均值，得到tensor (batch.size, seq.len)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        # 对x的最后一个维度，取标准方差，得(batch.size, seq.len)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "        # 本质上类似于（x-mean)/std，不过这里加入了两个可训练向量\n",
    "        # a_2 and b_2，以及分母上增加一个极小值epsilon，用来防止std为0的时候的除法溢出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.SubLayerConnection类主要实现两个功能，残差Add以及Norm（使用上面的LayerNorm类）：\n",
    "这个类，没有自己的可训练参数。(self.norm里面，即LayerNorm类，有1024个可训练参数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        # size=d_model=512; dropout=0.1\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size) # (512)，用来定义a_2和b_2\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        # x is alike (batch.size, sequence.len, 512)\n",
    "        # sublayer是一个具体的MultiHeadAttention\n",
    "        # 或者PositionwiseFeedForward对象\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "        # x (30, 10, 512) -> norm (LayerNorm) -> (30, 10, 512)\n",
    "        # -> sublayer (MultiHeadAttention or PositionwiseFeedForward)     ？？这里先norm了再sublayer\n",
    "        # -> (30, 10, 512) -> dropout -> (30, 10, 512)\n",
    "        \n",
    "        # 然后输入的x（没有走sublayer) + 上面的结果，\n",
    "        #即实现了残差相加的功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.PositionwiseFeedForward类相对简单，就是一个全连接层：\n",
    "\n",
    "FFN(x)=max(0,xW1+b1)W2+b2\n",
    "\n",
    "\n",
    "\n",
    "其中max(0, xW1 + b1) 是一个ReLU激活函数。\n",
    "\n",
    "上面的可训练参数包括两个权重矩阵，(512, 2048)以及(2048, 512)，以及两个偏移bias向量，(2048)和(512)。则总共的可训练参数的个数是：2*512*2048 + 2048 + 512 = 2,099,712。一个全连接层，轻松达到2百万个参数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        # d_model = 512\n",
    "        # d_ff = 2048 = 512*4\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        # 构建第一个全连接层，(512, 2048)，其中有两种可训练参数：\n",
    "        # weights矩阵，(512, 2048)，以及\n",
    "        # biases偏移向量, (2048)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        # 构建第二个全连接层, (2048, 512)，两种可训练参数：\n",
    "        # weights矩阵，(2048, 512)，以及\n",
    "        # biases偏移向量, (512)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape = (batch.size, sequence.len, 512)\n",
    "        # 例如, (30, 10, 512)\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "        # x (30, 10, 512) -> self.w_1 -> (30, 10, 2048)\n",
    "        # -> relu -> (30, 10, 2048) \n",
    "        # -> dropout -> (30, 10, 2048)\n",
    "        # -> self.w_2 -> (30, 10, 512)是输出的shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面这个clones方法，实现一个网络的深copy，也就是说一个新的对象，和原来的对象，完全分离，不分享任何存储空间：（从而保证可训练参数，都有自己的取值，梯度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.EncoderLayer的构成\n",
    "介绍了两个sublayer之后，我们来看看一个6.EncoderLayer的构成："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        # size=d_model=512\n",
    "        # self_attn = MultiHeadAttention对象, first sublayer\n",
    "        # feed_forward = PositionwiseFeedForward对象，second sublayer\n",
    "        # dropout = 0.1 (e.g.)\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        # 使用深度克隆方法，完整地复制出来两个SublayerConnection\n",
    "        self.size = size # 512\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        # x shape = (30, 10, 512)\n",
    "        # mask 是(batch.size, 10,10)的矩阵，类似于当前一个词w，有哪些词是w可见的\n",
    "        # 源语言的序列的话，所有其他词都可见，除了\"<blank>\"这样的填充；\n",
    "        # 目标语言的序列的话，所有w的左边的词，都可见。\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        # x (30, 10, 512) -> self_attn (MultiHeadAttention) \n",
    "        # shape is same (30, 10, 512) -> SublayerConnection \n",
    "        # -> (30, 10, 512)\n",
    "        return self.sublayer[1](x, self.feed_forward)\n",
    "        # x 和feed_forward对象一起，给第二个SublayerConnection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 另外稍微难理解的是这里使用了lambda来定义一个匿名函数，展开类似于：\n",
    "def lambda1(self, x, mask):\n",
    "  return self.self_attn(x, x, x, mask) \n",
    "# 然后把这个lambda1传递给self.sublayer[0]。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.Encoder类的实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        # layer = one EncoderLayer object, N=6\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N) \n",
    "        # 深copy，N=6，\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        # 定义一个LayerNorm，layer.size=d_model=512\n",
    "        # 其中有两个可训练参数a_2和b_2\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        # x is alike (30, 10, 512)\n",
    "        # (batch.size, sequence.len, d_model)\n",
    "        # mask是类似于(batch.size, 10, 10)的矩阵\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "            # 进行六次EncoderLayer操作\n",
    "        return self.norm(x)\n",
    "        # 最后做一次LayerNorm，最后的输出也是(30, 10, 512) shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  9.DecoderLayer\n",
    "开始进入Decoder部分。\n",
    "\n",
    "因为很多类都是重复使用的，我们看第一个不一样的类, 9.DecoderLayer，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, \"\n",
    "    \"and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "      # size = d_model=512,\n",
    "      # self_attn = one MultiHeadAttention object，目标语言序列的\n",
    "      # src_attn = second MultiHeadAttention object, 目标语言序列\n",
    "      # 和源语言序列之间的\n",
    "      # feed_forward 一个全连接层\n",
    "      # dropout = 0.1\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size # 512\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    "        # 需要三个SublayerConnection, 分别在\n",
    "        # self.self_attn, self.src_attn, 和self.feed_forward的后边\n",
    "\n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"Follow Figure 1 (right) for connections.\"\n",
    "        m = memory # (batch.size, sequence.len, 512) \n",
    "        # 来自源语言序列的Encoder之后的输出，作为memory\n",
    "        # 供目标语言的序列检索匹配：（类似于alignment in SMT)\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        # 通过一个匿名函数，来实现目标序列的自注意力编码\n",
    "        # 结果扔给sublayer[0]:SublayerConnection\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        # 通过第二个匿名函数，来实现目标序列和源序列的注意力计算\n",
    "        # 结果扔给sublayer[1]:SublayerConnection\n",
    "        return self.sublayer[2](x, self.feed_forward)\n",
    "        # 走一个全连接层，然后\n",
    "        # 结果扔给sublayer[2]:SublayerConnection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "    def __init__(self, layer, N):\n",
    "        # layer = DecoderLayer object\n",
    "        # N = 6\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        # 深度copy六次DecoderLayer\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        # 初始化一个LayerNorm\n",
    "\n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "            # 执行六次DecoderLayer\n",
    "        return self.norm(x)\n",
    "        # 执行一次LayerNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "    def __init__(self, d_model, vocab):\n",
    "        # d_model=512\n",
    "        # vocab = 目标语言词表大小\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "        # 定义一个全连接层，可训练参数个数是(512 * trg_vocab_size) + \n",
    "        # trg_vocab_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)\n",
    "        # x 类似于 (batch.size, sequence.length, 512)\n",
    "        # -> proj 全连接层 (30, 10, trg_vocab_size) = logits\n",
    "        # 对最后一个维度执行log_soft_max\n",
    "        # 得到(30, 10, trg_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F.log_softmax\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "\\log \\left[f\\left(x_{i}\\right)\\right]=\\log \\left(\\frac{e^{x_{i}}}{e^{x_{1}}+e^{x_{2}}+\\ldots+e^{x_{n}}}\\right) \\\\\n",
    "=\\log \\left(\\frac{\\frac{e^{x_{i}}}{e^{M}}}{\\frac{e^{x_{1}}}{e^{M}}+\\frac{e^{x_{2}}}{e^{M}}+\\ldots+\\frac{e^{x_{n}}}{e^{M}}}\\right)=\\log \\left(\\frac{e^{\\left(x_{i}-M\\right)}}{\\sum_{j}^{n} e^{\\left(x_{j}-M\\right)}}\\right) \\\\\n",
    "=\\log \\left(e^{\\left(x_{i}-M\\right)}\\right)-\\log \\left(\\sum_{j}^{n} e^{\\left(x_{j}-M\\right)}\\right)=\\left(x_{i}-M\\right)-\\log \\left(\\sum_{j}^{n} e^{\\left(x_{j}-M\\right)}\\right)\n",
    "\\end{array}\n",
    "$$\n",
    "来实现, 其中 $M=\\max \\left(x_{i}\\right), i=1,2, \\cdots, n,$ 即 $M$ 为所有 $x_{i}$ 中最大的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.最外边的EncoderDecoder类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. \n",
    "    Base for this and many other models.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        # Encoder对象\n",
    "        self.decoder = decoder\n",
    "        # Decoder对象\n",
    "        self.src_embed = src_embed\n",
    "        # 源语言序列的编码，包括词嵌入和位置编码\n",
    "        self.tgt_embed = tgt_embed\n",
    "        # 目标语言序列的编码，包括词嵌入和位置编码\n",
    "        self.generator = generator\n",
    "        # 生成器\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        return self.decode(self.encode(src, src_mask), src_mask,tgt, tgt_mask)\n",
    "        # 先对源语言序列进行编码，\n",
    "        # 结果作为memory传递给目标语言的编码器\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        # src = (batch.size, seq.length)\n",
    "        # src_mask 负责对src加掩码\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "        # 对源语言序列进行编码，得到的结果为\n",
    "        # (batch.size, seq.length, 512)的tensor\n",
    "\n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n",
    "        # 对目标语言序列进行编码，得到的结果为\n",
    "        # (batch.size, seq.length, 512)的tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.mask的构造函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    # e.g., size=10\n",
    "    attn_shape = (1, size, size) # (1, 10, 10)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    # triu: 负责生成一个三角矩阵，k-th对角线以下都是设置为0 \n",
    "    # 上三角中元素为1.\n",
    "    \n",
    "    return torch.from_numpy(subsequent_mask) == 0\n",
    "    # 反转上面的triu得到的上三角矩阵，修改为下三角矩阵。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.如何构造一个EncoderDecoder对象："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    # src_vocab = 源语言词表大小\n",
    "    # tgt_vocab = 目标语言词表大小\n",
    "    \n",
    "    c = copy.deepcopy # 对象的深度copy/clone\n",
    "    attn = MultiHeadedAttention(h, d_model) # 8, 512\n",
    "    # 构造一个MultiHeadAttention对象\n",
    "    \n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    # 512, 2048, 0.1\n",
    "    # 构造一个feed forward对象\n",
    "\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    # 位置编码\n",
    "\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        Generator(d_model, tgt_vocab))\n",
    "\n",
    "    # This was important from their code. \n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            # 基本思想是通过网络层时，输入和输出的方差相同，包括前向传播和后向传播。\n",
    "            # torch.nn.init.xavier_uniform_(tensor, gain=1) 均匀分布 \n",
    "            nn.init.xavier_uniform(p)\n",
    "    return model # EncoderDecoder 对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.然后调用make_model，得到一个对象："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.layers.0.self_attn.linears.0.weight torch.Size([512, 512])\n",
      "encoder.layers.0.self_attn.linears.0.bias torch.Size([512])\n",
      "encoder.layers.0.self_attn.linears.1.weight torch.Size([512, 512])\n",
      "encoder.layers.0.self_attn.linears.1.bias torch.Size([512])\n",
      "encoder.layers.0.self_attn.linears.2.weight torch.Size([512, 512])\n",
      "encoder.layers.0.self_attn.linears.2.bias torch.Size([512])\n",
      "encoder.layers.0.self_attn.linears.3.weight torch.Size([512, 512])\n",
      "encoder.layers.0.self_attn.linears.3.bias torch.Size([512])\n",
      "encoder.layers.0.feed_forward.w_1.weight torch.Size([2048, 512])\n",
      "encoder.layers.0.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.layers.0.feed_forward.w_2.weight torch.Size([512, 2048])\n",
      "encoder.layers.0.feed_forward.w_2.bias torch.Size([512])\n",
      "encoder.layers.0.sublayer.0.norm.a_2 torch.Size([512])\n",
      "encoder.layers.0.sublayer.0.norm.b_2 torch.Size([512])\n",
      "encoder.layers.0.sublayer.1.norm.a_2 torch.Size([512])\n",
      "encoder.layers.0.sublayer.1.norm.b_2 torch.Size([512])\n",
      "encoder.layers.1.self_attn.linears.0.weight torch.Size([512, 512])\n",
      "encoder.layers.1.self_attn.linears.0.bias torch.Size([512])\n",
      "encoder.layers.1.self_attn.linears.1.weight torch.Size([512, 512])\n",
      "encoder.layers.1.self_attn.linears.1.bias torch.Size([512])\n",
      "encoder.layers.1.self_attn.linears.2.weight torch.Size([512, 512])\n",
      "encoder.layers.1.self_attn.linears.2.bias torch.Size([512])\n",
      "encoder.layers.1.self_attn.linears.3.weight torch.Size([512, 512])\n",
      "encoder.layers.1.self_attn.linears.3.bias torch.Size([512])\n",
      "encoder.layers.1.feed_forward.w_1.weight torch.Size([2048, 512])\n",
      "encoder.layers.1.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.layers.1.feed_forward.w_2.weight torch.Size([512, 2048])\n",
      "encoder.layers.1.feed_forward.w_2.bias torch.Size([512])\n",
      "encoder.layers.1.sublayer.0.norm.a_2 torch.Size([512])\n",
      "encoder.layers.1.sublayer.0.norm.b_2 torch.Size([512])\n",
      "encoder.layers.1.sublayer.1.norm.a_2 torch.Size([512])\n",
      "encoder.layers.1.sublayer.1.norm.b_2 torch.Size([512])\n",
      "encoder.norm.a_2 torch.Size([512])\n",
      "encoder.norm.b_2 torch.Size([512])\n",
      "decoder.layers.0.self_attn.linears.0.weight torch.Size([512, 512])\n",
      "decoder.layers.0.self_attn.linears.0.bias torch.Size([512])\n",
      "decoder.layers.0.self_attn.linears.1.weight torch.Size([512, 512])\n",
      "decoder.layers.0.self_attn.linears.1.bias torch.Size([512])\n",
      "decoder.layers.0.self_attn.linears.2.weight torch.Size([512, 512])\n",
      "decoder.layers.0.self_attn.linears.2.bias torch.Size([512])\n",
      "decoder.layers.0.self_attn.linears.3.weight torch.Size([512, 512])\n",
      "decoder.layers.0.self_attn.linears.3.bias torch.Size([512])\n",
      "decoder.layers.0.src_attn.linears.0.weight torch.Size([512, 512])\n",
      "decoder.layers.0.src_attn.linears.0.bias torch.Size([512])\n",
      "decoder.layers.0.src_attn.linears.1.weight torch.Size([512, 512])\n",
      "decoder.layers.0.src_attn.linears.1.bias torch.Size([512])\n",
      "decoder.layers.0.src_attn.linears.2.weight torch.Size([512, 512])\n",
      "decoder.layers.0.src_attn.linears.2.bias torch.Size([512])\n",
      "decoder.layers.0.src_attn.linears.3.weight torch.Size([512, 512])\n",
      "decoder.layers.0.src_attn.linears.3.bias torch.Size([512])\n",
      "decoder.layers.0.feed_forward.w_1.weight torch.Size([2048, 512])\n",
      "decoder.layers.0.feed_forward.w_1.bias torch.Size([2048])\n",
      "decoder.layers.0.feed_forward.w_2.weight torch.Size([512, 2048])\n",
      "decoder.layers.0.feed_forward.w_2.bias torch.Size([512])\n",
      "decoder.layers.0.sublayer.0.norm.a_2 torch.Size([512])\n",
      "decoder.layers.0.sublayer.0.norm.b_2 torch.Size([512])\n",
      "decoder.layers.0.sublayer.1.norm.a_2 torch.Size([512])\n",
      "decoder.layers.0.sublayer.1.norm.b_2 torch.Size([512])\n",
      "decoder.layers.0.sublayer.2.norm.a_2 torch.Size([512])\n",
      "decoder.layers.0.sublayer.2.norm.b_2 torch.Size([512])\n",
      "decoder.layers.1.self_attn.linears.0.weight torch.Size([512, 512])\n",
      "decoder.layers.1.self_attn.linears.0.bias torch.Size([512])\n",
      "decoder.layers.1.self_attn.linears.1.weight torch.Size([512, 512])\n",
      "decoder.layers.1.self_attn.linears.1.bias torch.Size([512])\n",
      "decoder.layers.1.self_attn.linears.2.weight torch.Size([512, 512])\n",
      "decoder.layers.1.self_attn.linears.2.bias torch.Size([512])\n",
      "decoder.layers.1.self_attn.linears.3.weight torch.Size([512, 512])\n",
      "decoder.layers.1.self_attn.linears.3.bias torch.Size([512])\n",
      "decoder.layers.1.src_attn.linears.0.weight torch.Size([512, 512])\n",
      "decoder.layers.1.src_attn.linears.0.bias torch.Size([512])\n",
      "decoder.layers.1.src_attn.linears.1.weight torch.Size([512, 512])\n",
      "decoder.layers.1.src_attn.linears.1.bias torch.Size([512])\n",
      "decoder.layers.1.src_attn.linears.2.weight torch.Size([512, 512])\n",
      "decoder.layers.1.src_attn.linears.2.bias torch.Size([512])\n",
      "decoder.layers.1.src_attn.linears.3.weight torch.Size([512, 512])\n",
      "decoder.layers.1.src_attn.linears.3.bias torch.Size([512])\n",
      "decoder.layers.1.feed_forward.w_1.weight torch.Size([2048, 512])\n",
      "decoder.layers.1.feed_forward.w_1.bias torch.Size([2048])\n",
      "decoder.layers.1.feed_forward.w_2.weight torch.Size([512, 2048])\n",
      "decoder.layers.1.feed_forward.w_2.bias torch.Size([512])\n",
      "decoder.layers.1.sublayer.0.norm.a_2 torch.Size([512])\n",
      "decoder.layers.1.sublayer.0.norm.b_2 torch.Size([512])\n",
      "decoder.layers.1.sublayer.1.norm.a_2 torch.Size([512])\n",
      "decoder.layers.1.sublayer.1.norm.b_2 torch.Size([512])\n",
      "decoder.layers.1.sublayer.2.norm.a_2 torch.Size([512])\n",
      "decoder.layers.1.sublayer.2.norm.b_2 torch.Size([512])\n",
      "decoder.norm.a_2 torch.Size([512])\n",
      "decoder.norm.b_2 torch.Size([512])\n",
      "src_embed.0.lut.weight torch.Size([10, 512])\n",
      "tgt_embed.0.lut.weight torch.Size([10, 512])\n",
      "generator.proj.weight torch.Size([10, 512])\n",
      "generator.proj.bias torch.Size([10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-d66b98a84243>:30: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  nn.init.xavier_uniform(p)\n"
     ]
    }
   ],
   "source": [
    "# # Small example model.\n",
    "tmp_model = make_model(10, 10, 2)\n",
    "# src_vocab_size = 10\n",
    "# tgt_vocab_size = 10\n",
    "# N = 2, number for EncoderLayer and DecoderLayer\n",
    "\n",
    "for name, param in tmp_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.data.shape)\n",
    "    else:\n",
    "        print ('no gradient necessary', name, param.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.先从构建batch和mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"Object for holding a batch of data with mask during training.\"\n",
    "    def __init__(self, src, trg=None, pad=0):\n",
    "        # src: 源语言序列，(batch.size, src.seq.len)\n",
    "        # 二维tensor，第一维度是batch.size；第二个维度是源语言句子的长度\n",
    "        # 例如：[ [2,1,3,4], [2,3,1,4] ]这样的二行四列的，\n",
    "        # 1-4代表每个单词word的id\n",
    "        \n",
    "        # trg: 目标语言序列，默认为空，其shape和src类似\n",
    "        # (batch.size, trg.seq.len)，\n",
    "        #二维tensor，第一维度是batch.size；第二个维度是目标语言句子的长度\n",
    "        # 例如trg=[ [2,1,3,4], [2,3,1,4] ] for a \"copy network\"\n",
    "        # (输出序列和输入序列完全相同）\n",
    "        \n",
    "        # pad: 源语言和目标语言统一使用的 位置填充符号，'<blank>'\n",
    "        # 所对应的id，这里默认为0\n",
    "        # 例如，如果一个source sequence，长度不到4，则在右边补0\n",
    "        # [1,2] -> [1,2,0,0]\n",
    "        \n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "        # src = (batch.size, seq.len) -> != pad -> \n",
    "        # (batch.size, seq.len) -> usnqueeze ->\n",
    "        # (batch.size, 1, seq.len) 相当于在倒数第二个维度扩展\n",
    "        # e.g., src=[ [2,1,3,4], [2,3,1,4] ]对应的是\n",
    "        # src_mask=[ [[1,1,1,1], [1,1,1,1]] ]\n",
    "        if trg is not None:\n",
    "            self.trg = trg[:, :-1] # 重要\n",
    "            # trg 相当于目标序列的前N-1个单词的序列\n",
    "            #（去掉了最后一个词）\n",
    "            self.trg_y = trg[:, 1:]\n",
    "            # trg_y 相当于目标序列的后N-1个单词的序列\n",
    "            # (去掉了第一个词）\n",
    "            # 目的是(src + trg) 来预测出来(trg_y)，\n",
    "            # 这个在illustrated transformer中详细图示过。\n",
    "            self.trg_mask = self.make_std_mask(self.trg, pad)\n",
    "            self.ntokens = (self.trg_y != pad).data.sum()\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        # 这里的tgt类似于：\n",
    "        #[ [2,1,3], [2,3,1] ] （最初的输入目标序列，分别去掉了最后一个词\n",
    "        # pad=0, '<blank>'的id编号\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        # 得到的tgt_mask类似于\n",
    "        # tgt_mask = tensor([[[1, 1, 1]],[[1, 1, 1]]], dtype=torch.uint8)\n",
    "        # shape=(2,1,3)\n",
    "        tgt_mask = tgt_mask & Variable(subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n",
    "        # 先看subsequent_mask, 其输入的是tgt.size(-1)=3\n",
    "        # 这个函数的输出为= tensor([[[1, 0, 0],\n",
    "        # [1, 1, 0],\n",
    "        # [1, 1, 1]]], dtype=torch.uint8)\n",
    "        # type_as 把这个tensor转成tgt_mask.data的type(也是torch.uint8)\n",
    "        \n",
    "        # 这样的话，&的两边的tensor分别是(2,1,3), (1,3,3);\n",
    "        #tgt_mask = tensor([[[1, 1, 1]],[[1, 1, 1]]], dtype=torch.uint8)\n",
    "        #and\n",
    "        # tensor([[[1, 0, 0], [1, 1, 0], [1, 1, 1]]], dtype=torch.uint8)\n",
    "        \n",
    "        # (2,3,3)就是得到的tensor\n",
    "        # tgt_mask.data = tensor([[[1, 0, 0],\n",
    "        #                          [1, 1, 0],\n",
    "        #                          [1, 1, 1]],\n",
    "\n",
    "        #[[1, 0, 0],\n",
    "        # [1, 1, 0],\n",
    "        # [1, 1, 1]]], dtype=torch.uint8)\n",
    "        return tgt_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. 优化算法，这里使用Adam算法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # optimizer = Adam (Parameter Group 0\n",
    "        #    amsgrad: False\n",
    "        #    betas: (0.9, 0.98)\n",
    "        #    eps: 1e-09\n",
    "        #    lr: 0\n",
    "        #    weight_decay: 0\n",
    "        #)\n",
    "        self._step = 0\n",
    "        self.warmup = warmup # e.g., 4000 轮 热身\n",
    "        self.factor = factor # e.g., 2\n",
    "        self.model_size = model_size # 512\n",
    "        self._rate = 0\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate`(learning rate) above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "            (self.model_size ** (-0.5) *\n",
    "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
    "        \n",
    "def get_std_opt(model):\n",
    "    return NoamOpt(model.src_embed[0].d_model, 2, 4000,\n",
    "            torch.optim.Adam(model.parameters(), lr=0, \n",
    "            betas=(0.9, 0.98), eps=1e-9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'learning rate')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Three settings of the lrate hyperparameters.\n",
    "opts = [NoamOpt(512, 1, 4000, None), \n",
    "        NoamOpt(512, 1, 8000, None),\n",
    "        NoamOpt(256, 1, 4000, None)]\n",
    "plt.plot(np.arange(1, 20000), \n",
    "  [[opt.rate(i) for opt in opts] for i in range(1, 20000)])\n",
    "plt.legend([\"512:4000\", \"512:8000\", \"256:4000\"])\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('learning rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. LabelSmoothing\n",
    "下面进入有些难于理解的LabelSmoothing，简单思想就是劫富济贫。\n",
    "\n",
    "这个方法虽然会损害Perplexity，但是会增加最后的BLEU score.\n",
    "\n",
    "另外，这个名字不好，无论如何需要加上 KLLoss, 类似于：\n",
    "\n",
    "LabelSmoothing -> LabelSmoothingKLLoss 其实是最终计算损失函数的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    \"Implement label smoothing.\"\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(size_average=False)\n",
    "        self.padding_idx = padding_idx # '<blank>' 的id\n",
    "        self.confidence = 1.0 - smoothing # 自留的概率值、得分 e.g. 0.6\n",
    "        self.smoothing = smoothing # 均分出去的概率值，得分 e.g. 0.4\n",
    "        self.size = size # target vocab size 目标语言词表大小\n",
    "        self.true_dist = None\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        \"in real-world case: 真实情况下\"\n",
    "        #  x的shape为(batch.size * seq.len, target.vocab.size)\n",
    "        # y的shape是(batch.size * seq.len)\n",
    "        \n",
    "        # x=logits，(seq.len, target.vocab.size)\n",
    "        # 每一行，代表一个位置的词\n",
    "        # 类似于：假设seq.len=3, target.vocab.size=5\n",
    "        # x中保存的是log(prob)\n",
    "        #x = tensor([[-20.7233,  -1.6094,  -0.3567,  -2.3026, -20.7233],\n",
    "        #[-20.7233,  -1.6094,  -0.3567,  -2.3026, -20.7233],\n",
    "        #[-20.7233,  -1.6094,  -0.3567,  -2.3026, -20.7233]])\n",
    "        \n",
    "        # target 类似于：\n",
    "        # target = tensor([2, 1, 0])，torch.size=(3)\n",
    "        \n",
    "        assert x.size(1) == self.size # 目标语言词表大小\n",
    "        true_dist = x.data.clone()\n",
    "        # true_dist = tensor([[-20.7233,  -1.6094,  -0.3567,  -2.3026, -20.7233],\n",
    "        #[-20.7233,  -1.6094,  -0.3567,  -2.3026, -20.7233],\n",
    "        #[-20.7233,  -1.6094,  -0.3567,  -2.3026, -20.7233]])\n",
    "        \n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        # true_dist = tensor([[0.1333, 0.1333, 0.1333, 0.1333, 0.1333],\n",
    "        #[0.1333, 0.1333, 0.1333, 0.1333, 0.1333],\n",
    "        #[0.1333, 0.1333, 0.1333, 0.1333, 0.1333]])\n",
    "        \n",
    "        # 注意，这里分母target.vocab.size-2是因为\n",
    "        # (1) 最优值 0.6要占一个位置；\n",
    "        # (2) 填充词 <blank> 要被排除在外\n",
    "        # 所以被激活的目标语言词表大小就是self.size-2\n",
    "        \n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), \n",
    "          self.confidence)\n",
    "        # target.data.unsqueeze(1) -> \n",
    "        # tensor([[2],\n",
    "        #[1],\n",
    "        #[0]]); shape=torch.Size([3, 1])  \n",
    "        # self.confidence = 0.6\n",
    "        \n",
    "        # 根据target.data的指示，按照列优先(1)的原则，把0.6这个值\n",
    "        # 填入true_dist: 因为target.data是2,1,0的内容，\n",
    "        # 所以，0.6填入第0行的第2列（列号，行号都是0开始）\n",
    "        # 0.6填入第1行的第1列\n",
    "        # 0.6填入第2行的第0列：\n",
    "        # true_dist = tensor([[0.1333, 0.1333, 0.6000, 0.1333, 0.1333],\n",
    "        #[0.1333, 0.6000, 0.1333, 0.1333, 0.1333],\n",
    "        #[0.6000, 0.1333, 0.1333, 0.1333, 0.1333]])\n",
    "          \n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        # true_dist = tensor([[0.0000, 0.1333, 0.6000, 0.1333, 0.1333],\n",
    "        #[0.0000, 0.6000, 0.1333, 0.1333, 0.1333],\n",
    "        #[0.0000, 0.1333, 0.1333, 0.1333, 0.1333]])\n",
    "        # 设置true_dist这个tensor的第一列的值全为0\n",
    "        # 因为这个是填充词'<blank>'所在的id位置，不应该计入\n",
    "        # 目标词表。需要注意的是，true_dist的每一列，代表目标语言词表\n",
    "        #中的一个词的id\n",
    "        \n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        # mask = tensor([[2]]), 也就是说，最后一个词 2,1,0中的0，\n",
    "        # 因为是'<blank>'的id，所以通过上面的一步，把他们找出来\n",
    "        \n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "            # 当target reference序列中有0这个'<blank>'的时候，则需要把\n",
    "            # 这一行的值都清空。\n",
    "            # 在一个batch里面的时候，可能两个序列长度不一，所以短的序列需要\n",
    "            # pad '<blank>'来填充，所以会出现类似于(2,1,0)这样的情况\n",
    "            # true_dist = tensor([[0.0000, 0.1333, 0.6000, 0.1333, 0.1333],\n",
    "            # [0.0000, 0.6000, 0.1333, 0.1333, 0.1333],\n",
    "            # [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, \n",
    "          Variable(true_dist, requires_grad=False))\n",
    "          # 这一步就是调用KL loss来计算\n",
    "          # x = tensor([[-20.7233,  -1.6094,  -0.3567,  -2.3026, -20.7233],\n",
    "          #[-20.7233,  -1.6094,  -0.3567,  -2.3026, -20.7233],\n",
    "          #[-20.7233,  -1.6094,  -0.3567,  -2.3026, -20.7233]])\n",
    "          \n",
    "          # true_dist=tensor([[0.0000, 0.1333, 0.6000, 0.1333, 0.1333],\n",
    "          # [0.0000, 0.6000, 0.1333, 0.1333, 0.1333],\n",
    "          # [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n",
    "          # 之间的loss了。细节可以参考我的那篇illustrated transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'de'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-857b052b0375>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mspacy_de\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'de'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mspacy_en\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"exists\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Path or Path-like to model data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'de'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "# For data loading.\n",
    "from torchtext import data, datasets\n",
    "\n",
    "if True:\n",
    "    import spacy\n",
    "    spacy_de = spacy.load('de')\n",
    "    spacy_en = spacy.load('en')\n",
    "\n",
    "    def tokenize_de(text):\n",
    "        return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "    def tokenize_en(text):\n",
    "        return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "    BOS_WORD = '<s>'\n",
    "    EOS_WORD = '</s>'\n",
    "    BLANK_WORD = \"<blank>\"\n",
    "    SRC = data.Field(tokenize=tokenize_de, pad_token=BLANK_WORD)\n",
    "    TGT = data.Field(tokenize=tokenize_en, init_token = BOS_WORD, \n",
    "                     eos_token = EOS_WORD, pad_token=BLANK_WORD)\n",
    "\n",
    "    MAX_LEN = 100\n",
    "    train, val, test = datasets.IWSLT.splits(\n",
    "        exts=('.de', '.en'), fields=(SRC, TGT), \n",
    "        filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
    "            len(vars(x)['trg']) <= MAX_LEN)\n",
    "    MIN_FREQ = 2\n",
    "    SRC.build_vocab(train.src, min_freq=MIN_FREQ)\n",
    "    TGT.build_vocab(train.trg, min_freq=MIN_FREQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
